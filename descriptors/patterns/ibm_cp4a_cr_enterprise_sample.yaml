###############################################################################
##
##Licensed Materials - Property of IBM
##
##(C) Copyright IBM Corp. 2020. All Rights Reserved.
##
##US Government Users Restricted Rights - Use, duplication or
##disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
##
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: icp4adeploy
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 20.0.2
spec:
  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  appVersion: 20.0.2
  #################################################################################################################
  ##  The contents of this template CR file reflect only the specific parameters and configuration 
  ##  settings applicable to the represented ICP4A capability. 
  ##   
  ##  These values/configuration sections are to be used when manually assembling or updating the main 
  ##  ICP4A CR that is being applied in order to install an ICP4A environment. 
  ##  
  ##  If you are in the process of preparing a new install of an ICP4A environment, 
  ##  you should merge the required values and configuration sections from this file into the   
  ##  starting point CR template: ibm_cp4a_cr_enterprise_foundation.yaml available in the
  ##  same location as this template. 
  ##  
  ##  If you updating an existing ICP4A environment, you should merge the required values and configuration
  ##  sections from this template in the main ICP4A CR file already applied in the environment.  
  ##  
  ######################################################################################################################
  shared_configuration:
    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the rest of the licenses.
    sc_deployment_fncm_license: "non-production"
    ## Business Automation Workflow (BAW) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_baw_license: "non-production"
    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "non-production"
    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitlement Registry is used, then 
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.    
    sc_image_repository: cp.icr.io
    images:
      keytool_job_container:
        repository: cp.icr.io/cp/cp4a/ums/dba-keytool-jobcontainer
        tag: 20.0.2
      dbcompatibility_init_container:
        repository: cp.icr.io/cp/cp4a/aae/dba-dbcompatibility-initcontainer
        tag: 20.0.2
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/ums/dba-keytool-initcontainer
        tag: 20.0.2
      umsregistration_initjob:
        repository: cp.icr.io/cp/cp4a/aae/dba-umsregistration-initjob
        tag: 20.0.2
      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent
    ## All CP4A components must use/share the root_ca_secret in order for integration    
    root_ca_secret: icp4a-root-ca
    ## CP4A patterns or capabilities to be deployed. This CR represents Operational Decsision Manage "decisions" pattern
    ## that brings Decision Center, Rule Execution Server and Decision Runner, based on the user specification in the 
    ## sc_optional_components specification
    sc_deployment_patterns: "foundation,contentanalyzer,content,decisions,digitalworker,baw"
    ## The optional components to be installed if listed here.
    ## This is normally populated by the deploy script based on input from the user.
    ## User can also manually specify the optional components to be deployed here.
    ## This pattern has has 3: decisionCenter, decisionRunner, and decisionServerRuntime selectable components, where 
    ## decisionRuntime represent the Rule Execution Server. 
    ## If decisionCenter is set, you also have to set the 'odm_configuration.decisionCenter.enabled' flag to true to install it.
    ## If decisionRunner is set, you also have to set the 'odm_configuration.decisionRunner.enabled' flag to true to install it.
    ## If decisionServerRuntime is set, you also have to set the 'odm_configuration.decisionRuntime.enabled' flag to true to install it.
    sc_optional_components: "cmis,ums,bai"
    ## The deployment type as selected by the user.  Possible values are: demo, enterprise.    
    sc_deployment_type: "enterprise"
    ## The platform to be deployed specified by the user.  Possible values are: OCP, ROKS,IKS and other.  This is normally populated by the User script 
    ## based on input from the user.    
    sc_deployment_platform: "OCP"
    ## For OCP, this is used to create route, you should input a valid hostname in the required field.
    sc_deployment_hostname_suffix: "cp-automation.<registered-domain or <public ip of loadbalancer>.nip.io>"
    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of 
    ## the external service to the component's truststore.
    trusted_certificate_list: []
    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "enterprise" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.   
    storage_configuration:
      sc_slow_file_storage_classname: cp4a-file-retain-bronze-gid
      sc_medium_file_storage_classname: cp4a-file-retain-silver-gid
      sc_fast_file_storage_classname: cp4a-file-retain-gold-gid
    ##############################################################################################
    # Kafka client configuration for IBM Business Automation Insights and other ICP4A products.
    #
    # The customization of the following 4 parameters is "<Required>" only if you have
    # specificed "bai" as part of the sc_optional_components to specify that Business Automation
    # Insights must be installed.
    #
    # Otherwise, if Business Automation Insights is not being installed, there is no need to configure
    # these parameters and they can be kept empty.
    ##############################################################################################
    kafka_configuration:
      # Comma-separated list of hosts:port for connection to the Kafka cluster.
      # This field is mandatory for any Kafka configuration.
      bootstrap_servers: <eventstreams bootsrap server public route>:443
      # Value for the Kafka security.protocol property
      # Valid values: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL. Default: PLAINTEXT.
      security_protocol: SASL_SSL
      # Value for the Kafka sasl.mechanism property
      # Valid values: PLAIN, SCRAM-SHA-512. Default: PLAIN.
      sasl_mechanism: SCRAM-SHA-512
      # If the Kafka server requires authentication or uses SSL communications, the value of this field
      # must provide the name of a secret that holds the following keys as base64-encoded strings:
      # kafka-username: Kafka username; leave empty if no authentication
      # kafka-password: Kafka password; leave empty if no authentication
      # kafka-server-certificate: server certificate for SSL communications; leave empty if SSL protocol is not used
      # the below secret can be generated using script: scripts/pull-eventstreams-connection-info.sh. It creates the secret in eventstreams namespace. 
      # Copy values and create a similar secret, with name: icp4a-kafka-connection-secret in automation namespace.
      connection_secret_name: icp4a-kafka-connection-secret
    ## Specify the RunAsUser for the security context of the pod.  This is usually a numeric value that correponds to a user ID.
    sc_run_as_user:
    ## Shared encryption key secret name that is used for Workstream Services and Process Federation Server integration.
    encryption_key_secret: icp4a-shared-encryption-key
    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores, 
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section 
    ## is defined in the CR, then that configuration will take precedence overriding this parameter.  Note that if you are upgrading or
    ## migrating, set this parameter to "false" since the env has been previously initialized.
    sc_content_initialization: true
    ## Enable/disable the ECM (FNCM) / BAN verification (e.g., creation of test folder, creation of test document, 
    ## execution of CBR search, and creation of Navigator demo repository and desktop).  If the "verify_configuration" 
    ## section is defined in the CR, then that configuration will take precedence overriding this parameter.  Note that if you are upgrading or
    ## migrating, set this parameter to "false" since the env has been previously verified.
    sc_content_verification: true
    image_pull_secrets:
    - admin.registrykey
  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory"
    lc_selected_ldap_type: "IBM Security Directory Server"
    ## The name of the LDAP server to connect
    lc_ldap_server: "<LDAP server>"
    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "389"
    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret
    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "O=IBM,C=US"
    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: false
    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"
    ## The LDAP user name attribute.  One possible value is "*:cn" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "*:cn"
    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "cn"
    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "O=IBM,C=US"
    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"
    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"
    ## The LDAP group membership search filter string.  One possible value is "(&(cn=%v)(|(objectclass=groupOfNames)(objectclass=groupOfUniqueNames)(objectclass=groupOfURLs))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))"
    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "groupofnames:member"
    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(samAccountName=%v)(objectClass=user))"
    #   lc_group_filter: "(&(samAccountName=%v)(objectclass=group))"
    tds:
      lc_user_filter: "(&(cn=%v)(objectclass=person))"
      lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
      ## User script should only uncomment this section if External Share if selected as an optional component.
      ## If you are deploying without the User script, uncomment the necessary section (depending
      ## if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
      # ext_ldap_configuration:
      #   lc_selected_ldap_type: "IBM Security Directory Server"
      #   lc_ldap_server: "<Required>"
      #   lc_ldap_port: "<Required>"
      #   lc_bind_secret: ldap-bind-secret
      #   lc_ldap_base_dn: "<Required>"
      #   lc_ldap_ssl_enabled: true
      #   lc_ldap_ssl_secret_name: "<Required>"
      #   lc_ldap_user_name_attribute: "<Required>"
      #   lc_ldap_user_display_name_attr: "<Required>"
      #   lc_ldap_group_base_dn: "<Required>"
      #   lc_ldap_group_name_attribute: "<Required>"
      #   lc_ldap_group_display_name_attr: "cn"
      #   lc_ldap_group_membership_search_filter: "<Required>"
      #   lc_ldap_group_member_id_map: "<Required>"
    ## User script will uncomment the section needed based on user's input from User script.
    ## If you are deploying without the User script, uncomment the necessary section (depending
    ## if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.    
    # ad:
    ## This is the Global Catalog port for the LDAP
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(samAccountName=%v)(objectClass=user))"
    #   lc_group_filter: "(&(samAccountName=%v)(objectclass=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The database configuration for UMS (User Management Service)
    dc_ums_datasource:
      ## Provide the database type from your infrastructure. The possible values are "db2" or "oracle".  This should be the same as the
      ## other datasource configuration above. Db2 with HADR is automatically activated if dc_ums_oauth_alternate_hosts and dc_ums_oauth_alternate_ports
      ## are set.
      dc_ums_oauth_type: "db2"
      ## Provide the database server name or IP address of the database server.
      dc_ums_oauth_host: "<DB2 server>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521".
      dc_ums_oauth_port: "50000"
      ## Provide the name of the database for UMS.  For example: "UMSDB"
      dc_ums_oauth_name: "UMSDB"
      dc_ums_oauth_schema: OAuthDBSchema
      dc_ums_oauth_ssl: false
      dc_ums_oauth_ssl_secret_name:
      dc_ums_oauth_driverfiles:
      dc_ums_oauth_alternate_hosts:
      dc_ums_oauth_alternate_ports:
      ## The database database configuration for teamserver
      ## Provide the database type from your infrastructure. The possible values are "db2" or "oracle".  This should be the same as the
      ## other datasource configuration above. Db2 with HADR is automatically activated if dc_ums_teamserver_alternate_hosts and dc_ums_teamserver_alternate_ports
      ## are set.
      dc_ums_teamserver_type: "db2"
      dc_ums_teamserver_host: "<DB2 server>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521".
      dc_ums_teamserver_port: "50000"
      ## Provide the name of the database for UMS teamserver.  For example: "UMSDB"
      dc_ums_teamserver_name: "UMSDB"
      dc_ums_teamserver_ssl: false
      dc_ums_teamserver_ssl_secret_name:
      dc_ums_teamserver_driverfiles:
      dc_ums_teamserver_alternate_hosts:
      dc_ums_teamserver_alternate_ports:
    ## The database configuration for the GCD datasource for CPE
    dc_gcd_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".
      dc_database_type: "db2"
      ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
      dc_common_gcd_datasource_name: "FNGCDDS"
      ## The GCD XA datasource name. The default value is "FNGCDDSXA".
      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
      ## Provide the database server name or IP address of the database server.
      database_servername: "<DB2 server>"
      ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB"
      database_name: "GCDDB"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "50000"
    ## The database configuration for the object store 1 (OS1) datasource for CPE
    dc_os_datasources:
    - dc_database_type: "db2" ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".  This should be the same as the 
      ## The OS1 non-XA datasource name.  The default value is "FNOS1DS".
      dc_common_os_datasource_name: "FNOS1DS"
      ## The OS1 XA datasource name.  The default value is "FNOS1DSXA".
      dc_common_os_xa_datasource_name: "FNOS1DSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the 
      ## GCD configuration above.
      database_servername: "<DB2 server>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "OS1DB"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "50000"
    ## The database configuration for ICN (Navigator) - aka BAN (Business Automation Navigator)
    dc_icn_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".  This should be the same as the 
      ## GCD and object store configuration above.
      dc_database_type: "db2"
      ## Provide the ICN datasource name.  The default value is "ECMClientDS".
      dc_common_icn_datasource_name: "ECMClientDS"
      database_servername: "<DB2 server>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "50000"
      ## Provide the name of the database for ICN (Navigator).  For example: "ICNDB"
      database_name: "ICNDB1"
    ## The database configuration for ACA (Content Analyzer)
    dc_ca_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".    
      dc_database_type: "db2"
      ## Provide the primary database server name and if your database server name cannot be resolvable by DNS, then provide the corresponding IP address for the `database_IP` parameter below.
      database_servername: "<DB2 server>"
      ## Provide the name of the BASE database for ACA.  For example: "BASECA"
      database_name: "BASECA"
      ## Provide the names of the TENANT databases for ACA.
      tenant_databases:
      - "CATENANT"
      - "TENANT2"
      ## Provide the database server port.  For Db2, the default is "50000".   For Oracle, the default is "1521".
      database_port: "50000"
      ## Enable SSL/TLS for database communication. Refer to Knowledge Center for more info.
      dc_database_ssl_enabled: false
    dc_odm_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "oracle".
      dc_database_type: "db2"
      ## Provide the database server name or IP address of the database server.
      database_servername: "<DB2 server>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      dc_common_database_port: "50000"
      ## Provide the name of the database for ODM.  For example: "ODMDB"
      dc_common_database_name: "ODMDB"
      ## The name of the secret that contains the credentials to connect to the database.
      dc_common_database_instance_secret: "odm-db-secret"
  #-----------------------------------------------------------------------
  # Configuration for IBM Business Automation Application Studio required for some ICP4A capabilities.
  #-----------------------------------------------------------------------
  bastudio_configuration:
    #Adjust this one if you created the secret with name other than the default
    admin_secret_name: "{{ meta.name }}-bas-admin-secret"
    #Provide BAStudio default administrator ID
    admin_user: "orgadmin"
    database:
      #Provide the database server hostname for BAStudio use
      host: "<DB2 server>"
      #Provide the database name for BAStudio use
      # The database provided should be created by the BAStudio SQL script template.
      name: "BASTUDIO"
      #Provide the database server port for BAStudio use
      port: "50000"
      # If you want to enable database automatic client reroute (ACR) for HADR, you must configure alternative_host and alternative_port. Otherwise, leave them blank.
      alternative_host:
      alternative_port:
      type: db2
    #-----------------------------------------------------------------------
    #  App Engine Playback Server (playback_server) can be only one instance. This is different from App Engine (where application_engine_configuration is a list and you can deploy multiple instances).
    #-----------------------------------------------------------------------
    playback_server:
      #Adjust this one if you created the secret with name other than the default
      admin_secret_name: playback-server-admin-secret
      #Provide playback application engine default administrator ID
      admin_user: "orgadmin"
      database:
        #Provide the database server hostname for playback application engine use
        host: "<DB2 server>"
        #Provide the database name for playback application engine use
        name: "AESTUDIO"
        #Provide the database server port for playback application engine use
        port: "50000"
        ## If you set up DB2 HADR and want to use it, you must configure alternative_host and alternative_port. Otherwise, leave them blank.
        alternative_host:
        alternative_port:
        type: db2
  ########################################################################
  ########      IBM Operational Decision Manager configuration    ########
  ########################################################################
  odm_configuration:
    # To enable ODM Runtime.
    decisionServerRuntime:
      enabled: true
    # To enable the Authoring part
    decisionRunner:
      enabled: true
    decisionCenter:
      enabled: true
    
    customization:
      authSecretRef: odm-ums-websecurity-secret
  ########################################################################
  ########   IBM Business Automation Digital Worker               ########
  ########################################################################
  # You can further customize the adw_configuration section as explained in the knowledge center.
  # See ibm_cp4a_cr_enterprise_FC_digitalworker.yaml file in descriptors/patterns for all parameters and their default values.
  adw_configuration:
    designer:
      hostname: "https://designer.{{ shared_configuration.sc_deployment_hostname_suffix
        }}"
      service_type: Route
    runtime:
      hostname: "https://runtime.{{ shared_configuration.sc_deployment_hostname_suffix
        }}"
      service_type: Route
      persistence:
        storageClassName: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname}}"
    management:
      hostname: "https://management.{{ shared_configuration.sc_deployment_hostname_suffix
        }}"
      service_type: Route
      persistence:
        storageClassName: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname}}"
    mongo:
      persistence:
        storageClassName: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname}}"
    npmRegistry:
      persistence:
        storageClassName: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname}}"
        #baiKafka: If you want to monitor ADW with BAI, uncomment this block and provide the necessary parameters
      # specify the ingress topic where ADW events should be sent
      #topic: "{{ meta.name }}-ibm-bai-ingress"
  #baiElasticsearch:
  # specify the URL of elasticSearch
  #url: ""
  # specify the URL of kibana
  #kibanaUrl: ""

  ########################################################################
  ########   IBM User and Group Management Service configuration  ########
  ########################################################################
  ums_configuration:
    images:
      ums:
        repository: cp.icr.io/cp/cp4a/ums/ums
        tag: 20.0.2

  ########################################################################
  ########      IBM Business Automation Insights configuration    ########
  ########################################################################
  bai_configuration:
    imageCredentials:
      registry: cp.icr.io/cp/cp4a

    # Set to true to automatically create the OpenShift routes when sc_deployment_platform is set
    # to OCP or ROKS.
    createRoutes: true

    # Set to true to enable the Flink job for sending events to HDFS.
    ingestion:
      install: false

    # Set to true to enable the Flink job for Digital Worker.
    adw:
      install: false

    # Set to true to enable the Flink job for BAW.
    bpmn:
      install: false

    # Set to true to enable the Flink job for BAWAdv.
    bawadv:
      install: false

    # Set to true to enable the Flink job for ICM.
    icm:
      install: false

    # Set to true to enable the Flink job for ODM.
    odm:
      install: false

    # Set to true to enable the Flink job for Content.
    content:
      install: false


  initialize_configuration:
    ic_domain_creation:
      domain_name: "P8DOMAIN"
      encryption_key: "128"
    ic_ldap_creation:
      ic_ldap_admin_user_name:
      - "ceadmin"
      ic_ldap_admins_groups_name:
      - "P8Admins"
      ic_ldap_name: "ldap_name"
    ic_obj_store_creation:
      object_stores:
      - oc_cpe_obj_store_display_name: "OS01"
        oc_cpe_obj_store_symb_name: "OS01"
        oc_cpe_obj_store_conn:
          name: "objectstore1_connection"
          site_name: "InitialSite"
          dc_os_datasource_name: "FNOS1DS"
          dc_os_xa_datasource_name: "FNOS1DSXA"
        oc_cpe_obj_store_admin_user_groups:
        - "P8Admins"
        # Array of users
        oc_cpe_obj_store_basic_user_groups:
        oc_cpe_obj_store_addons: true
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        oc_cpe_obj_store_asa_name: "demo_storage"
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os01_storagearea1"
        oc_cpe_obj_store_enable_workflow: true
        oc_cpe_obj_store_workflow_region_name: "design_region_name"
        oc_cpe_obj_store_workflow_region_number: 1
        oc_cpe_obj_store_workflow_data_tbl_space: "DATA_TS"
        oc_cpe_obj_store_workflow_index_tbl_space: ""
        oc_cpe_obj_store_workflow_blob_tbl_space: ""
        oc_cpe_obj_store_workflow_admin_group: "P8Admins"
        oc_cpe_obj_store_workflow_config_group: "P8Admins"
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        oc_cpe_obj_store_workflow_locale: "en"
        oc_cpe_obj_store_workflow_pe_conn_point_name: "pe_conn_os1"
        # Enable the content event emitter only when deploying 
        # BAI and have shared_configuration.kafka_configuration defined in 
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false

        ## Configuration for the design object store
        ## Display name for the design object store to create
      - oc_cpe_obj_store_display_name: "DOS"
        ## ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "DOS"
        oc_cpe_obj_store_conn:
          ## ## Object store connection name
          name: "DOS_connection" #database connection name
          ## The name of the site
          site_name: "InitialSite"
          ## Add the name of the object store database
          dc_os_datasource_name: "FNDSDOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSDOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "P8Admins"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os02_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "designos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 2
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "DATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: ""
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: ""
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Admins"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Admins"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: "pe_conn_dos"

        ## Configuration for the target object store
        ## Display name for the target object store to create
      - oc_cpe_obj_store_display_name: "TOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "TOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "TOS_connection" #database connection name
          ## The name of the site
          site_name: "InitialSite"
          ## Add the name of the object store database
          dc_os_datasource_name: "FNDSTOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSTOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "P8Admins"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
         ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os03_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: true
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "targetos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 3
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "DATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: ""
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: ""
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Admins"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Admins"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: "cpe_conn_tos"
  
    ic_enable_cbr:
    - object_store_name: "OS01"
      class_name: "Document"
      indexing_languages: "en"
    ic_icn_init_info:
      icn_repos:
      - add_repo_id: "demo_repo1"
        add_repo_ce_wsi_url: "http://{{ meta.name }}-cpe-svc:9080/wsi/FNCEWS40MTOM/"
        add_repo_os_sym_name: "OS01"
        add_repo_os_dis_name: "OS01"
        add_repo_workflow_enable: false
        add_repo_work_conn_pnt: "pe_conn_os1:1"
        add_repo_protocol: "FileNetP8WSI"
      ## If you have more than 1 object store, uncomment this section for initialization of the object store.
      # - add_repo_id: "test_repo2"
      #   add_repo_ce_wsi_url: "http://{{ meta.name }}-cpe-svc:9080/wsi/FNCEWS40MTOM/"
      #   add_repo_os_sym_name: "OS02"
      #   add_repo_os_dis_name: "OS02"
      #   add_repo_workflow_enable: true
      #   add_repo_work_conn_pnt: "pe_conn_os02:1"
      #   add_repo_protocol: "FileNetP8WSI"
      icn_desktop:
      - add_desktop_id: "demo"
        add_desktop_name: "icn_desktop"
        add_desktop_description: "This is ICN desktop"
        add_desktop_is_default: false
        add_desktop_repo_id: "demo_repo1"
        add_desktop_repo_workflow_enable: false
  ########################################################################
  ######## IBM FileNet Content Manager Verification configuration ######
  ########################################################################
  ## After the initialization process (see section above), the verification process will take place.
  ## The verification process ensures that the FNCM and BAN components are functioning correctly.  The verification
  ## process includes creation of a CPE folder, a CPE document, a CBR search, verifying the workflow configuration,
  ## and validation of the ICN desktop.
  verify_configuration:
    vc_cpe_verification:
      vc_cpe_folder:
      - folder_cpe_obj_store_name: "OS01"
        folder_cpe_folder_path: "/TESTFOLDER"
      vc_cpe_document:
      - doc_cpe_obj_store_name: "OS01"
        doc_cpe_folder_name: "/TESTFOLDER"
        doc_cpe_doc_title: "test_title"
        DOC_CPE_class_name: "Document"
        doc_cpe_doc_content: "This is a simple document test"
        doc_cpe_doc_content_name: "doc_content_name"
      vc_cpe_cbr:
      - cbr_cpe_obj_store_name: "OS01"
        cbr_cpe_class_name: "Document"
        cbr_cpe_search_string: "is a simple"
      vc_cpe_workflow:
      - workflow_cpe_enabled: false
        workflow_cpe_connection_point: "pe_conn_os1"
    vc_icn_verification:
    - vc_icn_repository: "demo_repo1"
      vc_icn_desktop_id: "demo"


  ###########################################################################
  ## This section contains the app engine component configurations #
  ###########################################################################
  application_engine_configuration:
  ## The application_engine_configuration is a list. You can deploy multiple instances of App Engine and assign different configurations for each instance.
  ## For each instance, application_engine_configuration.name and application_engine_configuration.name.hostname must have different values.
  - name: workspace
    #Adjust this one if you created the secret with name other than the default
    admin_secret_name: "ae-secret-credential"
    #Provide application engine default administrator ID
    admin_user: "ceadmin"
    database:
      #Provide the database server hostname for application engine use
      host: "<DB2 server>"
      #Provide the database name for application engine use
      name: "APPENGDB"
      #Provide the database server port for application engine use
      port: "50000"
      ## If you set up DB2 HADR and want to use it, you must configure alternative_host and alternative_port. Otherwise, leave them blank.
      alternative_host:
      alternative_port:
      type: db2

  ### CA configuration ###

  ca_configuration:
    global:
      arch: "amd64"
      # The database secret name created as part of the pre-req.  Default will be "aca-basedb" if blank.
      # Redis configuration
      redis:
        resources:
          limits:
            memory: "1000Mi"
            cpu: "0.5"
        replica_count: 3
      # RabbitMQ configuration
      rabbitmq:
        resources:
          limits:
            memory: "1200Mi"
            cpu: "1.2"
        replica_count: 3
    # Caller_api configuration
    caller_api:
      replica_count: 2
      resources:
        limits:
          memory: "1200Mi"
          cpu: "1"
    # Backend configuration
    spbackend:
      # Allow to specify a specific port (nodePort) for backend.  The port number must be between 30000-32767.  A random port will be generated if blank.
      port:
      replica_count: 2
      resources:
        limits:
          memory: "640Mi"
          cpu: "0.6"
    # Frontend configuration
    spfrontend:
      # Allow to specify a specific port (nodePort) for frontend.  The port number must be between 30000-32767.  A random port will be generated if blank.
      port:
      replica_count: 2
      resources:
        limits:
          memory: "480Mi"
          cpu: "0.6"
      backend_host: ""
      frontend_host: ""
    # Postprocessing configuration
    postprocessing:
      process_timeout: 1500
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "800Mi"
          cpu: "1"
    # Pdfprocess configuration
    pdfprocess:
      process_timeout: 1500
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "1500Mi"
          cpu: "1.2"
    # utfprocess configuration
    utfprocess:
      process_timeout: 1500
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "960Mi"
          cpu: "1.5"
    # setup configuration
    setup:
      process_timeout: 120
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "480Mi"
          cpu: "0.6"
    # ocrextraction configuration
    ocrextraction:
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "1440Mi"
          cpu: "1.5"
    # classifyprocess configuration
    classifyprocess:
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "960Mi"
          cpu: "1.5"
    # processingextraction configuration
    processingextraction:
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "1440Mi"
          cpu: "1"
    # updatefiledetail configuration
    updatefiledetail:
      replica_count: 2
      max_unavailable_count: 1
      resources:
        limits:
          memory: "480Mi"
          cpu: "0.6"


  ########################################################################
  ########   IBM Business Automation Workflow configuration     ########
  ########################################################################
  baw_configuration:
  ## The baw_configuration is a list. You can deploy multiple instances of Workflow server and assign different configurations for each instance.
  ## For each instance, baw_configuration.name and baw_configuration.name.hostname must have different values.
  - name: instance1
    ## If config the Process Portal for a federated environment
    host_federated_portal: true
    ## Workflow server service type.
    service_type: "Route"
    ## Workflow server hostname
    hostname: ""
    ## Workflow server port
    port: 443
    ## Workflow server nodeport
    nodeport: 30026
    ## Workflow server environment type. The possible value are "Development" or "Test" or "Staging" or "Production"
    env_type: "Development"
    ## Workflow server capability
    capabilities: "workflow"
    ## Workflow server replica count
    replicas: 1
    ## Provide Workflow server default administrator ID
    admin_user: "<Required>"  ##SACHINKJ - NOT SURE.
    ## The name of Workflow server admin secret
    admin_secret_name: "baw-admin-secret"   ##SACHINKJ - NOT SURE
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    # For scenario that customer has implemented their own Portal. E,g https://portal.mycompany.com
    customized_portal_endpoint: ""
    federated_portal:
      ## Content security policy additional origins for federate on premise BAW systems. E.g ["https://on-prem-baw1","https://on-prem-baw2"]
      content_security_policy_additional_origins: []
    external_connection_timeout: ""

    tls:
      ## Workflow server TLS secret that contains tls.key and tls.crt.
      tls_secret_name: ibm-baw-tls
      ## Workflow server TLS trust list.
      tls_trust_list:

    image:
      ## Workflow image repository URL
      repository: cp.icr.io/cp/cp4a/baw/workflow-server
      ## Image tag for Workflow server container
      tag: 20.0.2
      ## Pull policy for Workflow container
      pullPolicy: IfNotPresent
    pfs_bpd_database_init_job:
      ## Database initialization image repository URL for Process Federation Server
      repository: cp.icr.io/cp/cp4a/baw/pfs-bpd-database-init-prod
      ## Image tag for database initialization for Process Federation Server
      tag: 20.0.2
      ## Pull policy for Process Federation Server database initialization image
      pullPolicy: IfNotPresent
    upgrade_job:
      ## Workflow server database handling image repository URL
      repository: cp.icr.io/cp/cp4a/baw/workflow-server-dbhandling
      ## Image tag for Workflow server database handling
      tag: 20.0.2
      ## Pull policy for Workflow server database handling
      pullPolicy: IfNotPresent
    bas_auto_import_job:
      ## BAS toolkit init image repository URL
      repository: cp.icr.io/cp/cp4a/baw/toolkit-installer
      ## Image tag for BAS toolkit init image
      tag: 20.0.2
      ## Pull policy for BAS toolkit init image
      pullPolicy: IfNotPresent

    ## The database configuration for Workflow server
    database:
      ## Whether to enable Secure Sockets Layer (SSL) support for the Workflow server database connection
      ssl: false
      ## Secret name for storing the database TLS certificate when an SSL connection is enabled
      sslsecretname: ""
      ## Workflow server database type
      type: "DB2"
      ## Workflow server database server name.
      server_name: "<DB2 server>"
      ## Workflow server database name
      database_name: "BAWDB"
      ## Workflow server database port. For DB2, the default value is "50000"
      port: "50000"
      ## Workflow server database secret name
      secret_name: "ibm-baw-wfs-server-db-secret"
      ## Workflow server database connect pool maximum number of physical connections
      cm_max_pool_size: 200
      dbcheck:
        # The maximum waiting time (seconds) to check the database intialization status
        wait_time: 900
        # The interval time (seconds) to check.
        interval_time: 15
      

    ## The configurations for content integration
    content_integration:
      init_job_image:
        ## Image name for content integration container.
        repository: cp.icr.io/cp/cp4a/baw/iaws-ps-content-integration
        ## Image tag for content integration container
        tag: 20.0.2
        ## Pull policy for content integration container.
        pull_policy: IfNotPresent
      ## Domain name for content integration
      domain_name: "P8DOMAIN"
      ## Object Store name for content integration
      object_store_name: "OS01"
      ## Admin secret for content integration
      cpe_admin_secret: ""   ## SACHINKJ NOT SURE ABOUT KEYS TO USE

    ## The configuration for case
    case:
      init_job_image:
        ## Image name for CASE init job container.
        repository: cp.icr.io/cp/cp4a/baw/workflow-server-case-initialization
        ## Image tag for CASE init job container.
        tag: 20.0.2
        ## Pull policy for CASE init job container.
        pull_policy: IfNotPresent

      ## Domain name for CASE
      domain_name: "P8DOMAIN"
      ## Design Object Store name of CASE
      object_store_name_dos: "DOS"
      ## Target Object Store name of CASE
      object_store_name_tos: "TOS"
      ## Connection point name for Target Object Store
      connection_point_name_tos: "cpe_conn_tos"

      ## PVC name for CASE network shared directory
      network_shared_directory_pvc: "<Required>"
      ## The custom package names if need to install custom package, the value format like "package1.zip, package2,zip"
      custom_package_names: ""
      ## The custom extension names if need to install custom extension, the value format like "extension1.zip, extension2,zip"
      custom_extension_names: ""
      ## The event emitter settings if you want to enable Case Event Emitter
      event_emitter:
        date_sql:
        logical_unique_id:
        solution_list:

    ## Workflow center configuration
    workflow_center:
      ## The URL of workflow center
      url: "baw.lti-gsilab-ibmcloud.com"
      # The secret name of workflow center that contains username and password
      secret_name: ""
      # The hearbeat interval(seconds) to connect to workflow center
      heartbeat_interval: 30

    ## The configuration for Resource Registry if you want to use external Resource Registry
    resource_registry:
      ## Resource Registry host name
      hostname: ""
      ## Resource Registry port
      port: 443
      ## Resource Registry administrative secret
      admin_secret_name: ""

    ## The configuration for Java Messaging Service(JMS)
    jms:
      image:
        ## Image name for Java Messaging Service container
        repository: cp.icr.io/cp/cp4a/baw/jms
        ## Image tag for Java Messaging Service container
        tag: 20.0.2
        ## Pull policy for Java Messaging Service container
        pull_policy: IfNotPresent
      tls:
        ## TLS secret name for Java Message Service (JMS)
        tls_secret_name: ibm-jms-tls-secret
      resources:
        limits:
          ## Memory limit for JMS configuration
          memory: "2Gi"
          ## CPU limit for JMS configuration
          cpu: "1000m"
        requests:
          ## Requested amount of memory for JMS configuration
          memory: "512Mi"
          ## Requested amount of CPU for JMS configuration
          cpu: "200m"
      storage:
        ## Whether to enable persistent storage for JMS
        persistent: true
        ## Size for JMS persistent storage
        size: "1Gi"
        ## Whether to enable dynamic provisioning for JMS persistent storage
        use_dynamic_provisioning: true
        ## Access modes for JMS persistent storage
        access_modes:
        - ReadWriteOnce
        ## Storage class name for JMS persistent storage
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"

    ## Resource configuration
    resources:
      limits:
        ## CPU limit for Workflow server.
        cpu: 2
        ## Memory limit for Workflow server
        memory: 2096Mi
      requests:
        ## Requested amount of CPU for Workflow server
        cpu: "500m"
        ## Requested amount of memory for Workflow server.
        memory: 1048Mi

    ## liveness and readiness probes configuration
    probe:
      ws:
        liveness_probe:
          ## Number of seconds after the Workflow server container starts before the liveness probe is initiated
          initial_delay_seconds: 300
        readinessProbe:
          ## Number of seconds after the Workflow server container starts before the readiness probe is initiated
          initial_delay_seconds: 240

    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## Format for printing message logs on the console
      message_format: "basic"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"

    ## storage configuration
    storage:
      ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_dumpstore
      use_dynamic_provisioning: true
      ## The persistent volume claim for logs
      existing_pvc_for_logstore: ""
      ## The minimum size of the persistent volume used mounted as log store
      size_for_logstore: "10Gi"
      ## The persistent volume claim for dump files
      existing_pvc_for_dumpstore: ""
      ## The minimum size of the persistent volume used mounted as dump store
      size_for_dumpstore: "10Gi"

    ## JVM options separated with space, for example: -Dtest1=test -Dtest2=test2
    jvm_customize_options:

    ##  Workflow server custom plain XML snippet
    ##  liberty_custom_xml: |+
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    liberty_custom_xml:

    ##  Workflow server custom XML secret name that contains custom configuraiton in Liberty server.xml
    custom_xml_secret_name:

    ##  Workflow server Lombardi custom XML secret name that contains custom configuraiton in 100Custom.xml
    lombardi_custom_xml_secret_name:

    ##  IBM Business Automation Insights integration configuration
    business_event:
      enable: false
      enable_task_record: true
      enable_task_api: false
      subscription:
      - {'app_name': '*','version': '*','component_type': '*','component_name': '*','element_type': '*','element_name': '*','nature': '*'}

########################################################################
  ########   IBM Process Federation Server configuration          ########
  ########################################################################
  pfs_configuration:
    ## Process Federation Server hostname
    hostname: ""
    ## Process Federation Server port
    port: 443
    ## How the HTTPS endpoint service should be published. Possible values are ClusterIP, NodePort, Route
    service_type: Route

    ## If use the external elasticsearch server, provide the following configuration
    external_elasticsearch:
      ## The endpoint of external elasticearch, such as: https://<external_es_host>:<external_es_port>
      endpoint: ""
      ## The external elasticsearch administrative secret
      admin_secret_name: ""

    image:
      ## Process Federation Server image
      repository: cp.icr.io/cp/cp4a/baw/pfs-prod
      ## Process Federation Server image tag
      tag: "20.0.2"
      ## Process Federation Server image pull policy
      pull_policy: IfNotPresent

    ## Number of initial Process Federation Server pods
    replicas: 1
    ## Service account name for Process Federation Server pod
    service_account:
    ## Whether Kubernetes can (soft) or must not (hard) deploy Process Federation Server pods onto the same node. Possible values are "soft" and "hard".
    anti_affinity: hard
    
    ## Whether to enable default security roles  and possible values are: true and false
    enable_default_security_roles: true
    ## Name of the secret containing the Process Federation Server administration passwords, such as ltpaPassword, oidcClientPassword, sslKeyPassword
    admin_secret_name: ibm-pfs-admin-secret
    ## Name of the secret containing the files that will be mounted in the /config/configDropins/overrides folder
    config_dropins_overrides_secret: ""
    ## Name of the secret containing the files that will be mounted in the /config/resources/security folder
    resources_security_secret: ""
    ## Name of the custom libraries containing the files that will be mounted in the /config/resources/libs folder
    custom_libs_pvc: ""
    ## Whether to enable notification server and possible values are: true and false
    enable_notification_server: false
    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use the customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use the customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:

    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    tls:
      ## Existing TLS secret containing tls.key and tls.crt
      tls_secret_name:
      ## Existing TLS trust secret list
      tls_trust_list:

    resources:
      requests:
        ## Requested amount of CPU for PFS configuration
        cpu: 500m
        ## Requested amount of memory for PFS configuration
        memory: 512Mi
      limits:
        ## CPU limit for PFS configuration
        cpu: 2
        ## Memory limit for PFS configuration
        memory: 4Gi

    liveness_probe:
      ## Number of seconds after Process Federation Server container starts before the liveness probe is initiated
      initial_delay_seconds: 300
    readiness_probe:
      ## Number of seconds after Process Federation Server container starts before the readiness probe is initiated
      initial_delay_seconds: 240

    saved_searches:
      ## Name of the Elasticsearch index used to store saved searches
      index_name: ibmpfssavedsearches
      ## Number of shards of the Elasticsearch index used to store saved searches
      index_number_of_shards: 3
      ## Number of replicas (pods) of the Elasticsearch index used to store saved searches
      index_number_of_replicas: 1
      ## Batch size used when retrieving saved searches
      index_batch_size: 100
      ## Amount of time before considering an update lock as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      update_lock_expiration: 5m
      ## Amount of time before considering a unique constraint as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      unique_constraint_expiration: 5m

    security:
      sso:
        ## The ssoDomainNames property of the <webAppSecurity> tag
        domain_name:
        ## The ssoCookieName property of the <webAppSecurity> tag
        cookie_name: "ltpatoken2"
        ltpa:
          ## The keysFileName property of the <ltpa> tag
          filename: "ltpa.keys"
          ## The expiration property of the <ltpa> tag
          expiration: "120m"
          ## The monitorInterval property of the <ltpa> tag
          monitor_interval: "60s"
      ## The sslProtocol property of the <ssl> tag used as default SSL config
      ssl_protocol: SSL

    executor:
      ## Value of the maxThreads property of the <executor> tag
      max_threads: "80"
      ## Value of the coreThreads property of the <executor> tag
      core_threads: "40"

    rest:
      ## Value of the userGroupCheckInterval property of the <ibmPfs_restConfig> tag
      user_group_check_interval: "300s"
      ## Value of the systemStatusCheckInterval property of the <ibmPfs_restConfig> tag
      system_status_check_interval: "60s"
      ## Value of the bdFieldsCheckInterval property of the <ibmPfs_restConfig> tag
      bd_fields_check_interval: "300s"

    custom_env_variables:
      ## Names of the custom environment variables defined in the secret referenced in pfs.customEnvVariables.secret
      names:
      # - name: MY_CUSTOM_ENVIRONMENT_VARIABLE
      ## Secret holding custom environment variables
      secret:

    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## Format for printing message logs on the console
      message_format: "basic"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"
      storage:
        ## Use Dynamic Provisioning for PFS Logs Data Storage
        use_dynamic_provisioning: true
        ## The minimum size of the persistent volume used mounted as PFS Liberty server /logs folder
        size: 5Gi
        ## Storage class of the persistent volume used mounted as PFS Liberty server /logs folder
        storage_class: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname }}"

    ## When PFS is deployed in a environment that includes the Resource Registry ,
    ## the following additional parameters can be used to configure the integration between PFS and the Resource Registry
    dba_resource_registry:
      ## Time to live of the lease that creates the PFS entry in the DBA Resource Registry, in seconds.
      lease_ttl: 120
      ## The interval at which to check that PFS is running, in seconds.
      pfs_check_interval: 10
      ## The number of seconds after which PFS will be considered as not running if no connection can be perfomed
      pfs_connect_timeout: 10
      ## The number of seconds after which PFS will be considered as not running if has not yet responded
      pfs_response_timeout: 30
      ## The key under which PFS should be registered in the DBA Service Registry when running
      pfs_registration_key: /dba/appresources/IBM_PFS/PFS_SYSTEM
      resources:
        limits:
          ## Memory limit for PFS and RR integration pod
          memory: '512Mi'
          ## CPU limit for PFS and RR integration pod
          cpu: '500m'
        requests:
          ## Requested amount of memory for PFS and RR integration pod
          memory: '512Mi'
          ## Requested amount of CPU for PFS and RR integration pod
          cpu: '200m'

  ########################################################################
  ########   Embedded Elasticsearch configuration                 ########
  ########################################################################
  elasticsearch_configuration:
    es_image:
      ## Elasticsearch image
      repository: cp.icr.io/cp/cp4a/baw/pfs-elasticsearch-prod
      ## Elasticsearch image tag
      tag: "20.0.2"
      ## Elasticsearch image pull policy
      pull_policy: IfNotPresent
    es_init_image:
      ## The image used by the privileged init container to configure Elasticsearch system settings.
      ## This value is only relevant if elasticsearch_configuration.privileged is set to true
      repository: cp.icr.io/cp/cp4a/baw/pfs-init-prod
      ## The image tag for Elasticsearch init container
      tag: "20.0.2"
      ## The pull policy for Elasticsearch init container
      pull_policy: IfNotPresent
    es_nginx_image:
      ## The name of the Nginx docker image to be used by Elasticsearch pods
      repository: cp.icr.io/cp/cp4a/baw/pfs-nginx-prod
      ## The image tag of the Nginx docker image to be used by Elasticsearch pods
      tag: "20.0.2"
      ## The pull policy for the Nginx docker image to be used by Elasticsearch pods
      pull_policy: IfNotPresent

    ## Number of initial Elasticsearch pods
    replicas: 1
    ## How the HTTPS endpoint service should be published. The possible values are ClusterIP and NodePort
    service_type: ClusterIP
    ## The port to which the Elasticsearch server HTTPS endpoint will be exposed externally.
    ## This parameter is relevant only if elasticsearch_configuration.service_type is set to NodePort
    external_port:
    ## The elasticsearch admin secret that contains the username, password and .htpasswd.
    ## If not provided, the defualt admin secret named "{{ meta.name }}-elasticsearch-admin-secret" is used.
    admin_secret_name:
    ## Whether Kubernetes "may" (soft) or "must not" (hard) deploy Elasticsearch pods onto the same node
    ## The possible values are "soft" and "hard"
    anti_affinity: hard
    ## Name of a service account to use.
    ## If elasticsearch_configuration.privileged is set to true, then this service account must allow running privileged containers.
    ## If not provided, the default service account named "{{ meta.name }}-elasticsearch-service-account" is used.
    service_account:
    ## When set to true, a privileged container will be created to execute the appropriate sysctl commands so that the node running the pods matches the elasticsearch requirements.
    privileged: true
    ## Initial delay for liveness and readiness probes of Elasticsearch pods
    probe_initial_delay: 90
    ## The JVM heap size to allocate to each Elasticsearch pod
    heap_size: "1024m"
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    resources:
      limits:
        ## Memory limit for Elasticsearch configuration
        memory: "2Gi"
        ## CPU limit for Elasticsearch configuration
        cpu: "1000m"
      requests:
        ## Requested amount of memory for Elasticsearch configuration
        memory: "1Gi"
        ## Requested amount of CPU for Elasticsearch configuration
        cpu: "100m"

    storage:
      ## If persistent the elasticsearch data. Set to false for non-production or trial-only deployment.
      persistent: true
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 10Gi
      ## Storage class name for Elasticsearch persistent storage
      storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"

    snapshot_storage:
      ## If persistent the elasticsearch snapshot storage. Set to true for production deployment.
      enabled: false
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 30Gi
      ## Storage class name for Elasticsearch persistent snapshot storage
      storage_class_name: ""
      ## By default, a new persistent volume claim is be created. Specify an existing claim here if one is available.
      existing_claim_name: ""
